{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "556e7f69",
        "outputId": "b53048bb-1564-4946-8ee7-f82061e3fe89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/content/requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r /content/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspaces/PDF-OCR-RAG-Tool\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfZxDgVEJquj",
        "outputId": "a65c1168-4529-4a63-e413-8cf66bdd0af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ab1c00"
      },
      "source": [
        "# Task\n",
        "Amend the `app.py` file to:\n",
        "1. Display the full text of the document after OCR.\n",
        "2. Add a RAG (Retrieval-Augmented Generation) function after the summary is provided. This function should allow for multiple queries of all uploaded documents until the user types 'exit'.\n",
        "3. Include instructions for users on how to use the RAG functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e538e0ab"
      },
      "source": [
        "## Display extracted text\n",
        "\n",
        "### Subtask:\n",
        "Modify the `app.py` file to display the full text extracted from the PDF(s) after the OCR process is complete. This will appear before the summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dfbf461"
      },
      "source": [
        "**Reasoning**:\n",
        "I will modify the `app.py` file to display the extracted text from the PDF. I will add a subheader and a text area to show the `all_pdf_text` content before the summarization part, as requested in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6151f9f"
      },
      "source": [
        "## Implement rag chat\n",
        "\n",
        "### Subtask:\n",
        "Add a new section to the Streamlit interface titled \"Chat with your Documents (RAG)\". This section will appear after the summary and will include a text input field for you to ask questions about the uploaded documents. The application should also allow for multiple questions until the user types \"exit\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bfa94e3"
      },
      "source": [
        "**Reasoning**:\n",
        "I will overwrite the `app.py` file with the provided code, which includes the necessary changes for this subtask. I will add a new section with the subheader \"Chat with your Documents (RAG)\" after the summary section in the `main` function. Inside this new section, I will add a `st.text_input` field to get the user's query and implement a `while` loop that continues to prompt for input until the user enters \"exit\". Inside the loop, if the query is not \"exit\", I will use the existing `qa_chain` to get the answer and display it using `st.write`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8856c7"
      },
      "source": [
        "**Reasoning**:\n",
        "The `app.py` file has been updated. Now, I will restart the Streamlit application to apply the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972b919c",
        "outputId": "fa5bd4f3-8c3b-4786-99d0-a72fa2953598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import openai\n",
        "import pdf2image\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_openai import ChatOpenAI\n",
        "import streamlit as st\n",
        "import tiktoken\n",
        "\n",
        "def pdf_to_img(pdf_file):\n",
        "    \"\"\"Converts a PDF file to a list of PIL Images.\"\"\"\n",
        "    return pdf2image.convert_from_path(pdf_file)\n",
        "\n",
        "\n",
        "def ocr_core(file):\n",
        "    \"\"\"Performs OCR on a single image and returns the extracted text.\"\"\"\n",
        "    return pytesseract.image_to_string(file)\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Extracts text from all pages of a PDF file.\"\"\"\n",
        "    images = pdf_to_img(pdf_file)\n",
        "    extracted_text = \"\"\n",
        "    for img in images:\n",
        "        extracted_text += ocr_core(img) + \"\\n\\n\"\n",
        "    return extracted_text\n",
        "\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    \"\"\"Counts the number of tokens in a string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "def main():\n",
        "    \"\"\"Orchestrates the script's execution with a Streamlit GUI.\"\"\"\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    openai.api_key = openai_api_key\n",
        "\n",
        "    st.title(\"PDF OCR & Summarize & RAG\")\n",
        "\n",
        "    with st.expander(\"IMPORTANT NOTICE\"):\n",
        "        st.write(\"\"\"\n",
        "        This web application is a prototype developed for educational purposes only. The information provided here is NOT intended for real-world usage and should not be relied upon for making any decisions, especially those related to financial, legal, or healthcare matters.\n",
        "\n",
        "        Furthermore, please be aware that the LLM may generate inaccurate or incorrect information. You assume full responsibility for how you use any generated output.\n",
        "\n",
        "        Always consult with qualified professionals for accurate and personalized advice.\n",
        "        \"\"\")\n",
        "\n",
        "    uploaded_files = st.file_uploader(\n",
        "        \"Upload PDF files\", type=\"pdf\", accept_multiple_files=True\n",
        "    )\n",
        "\n",
        "    if \"qa_chain\" not in st.session_state:\n",
        "        st.session_state.qa_chain = None\n",
        "\n",
        "    if uploaded_files:\n",
        "        all_pdf_text = \"\"\n",
        "        for uploaded_file in uploaded_files:\n",
        "            try:\n",
        "                with open(uploaded_file.name, \"wb\") as f:\n",
        "                    f.write(uploaded_file.getbuffer())\n",
        "                pdf_text = extract_text_from_pdf(uploaded_file.name)\n",
        "                all_pdf_text += pdf_text\n",
        "                st.success(f\"Successfully extracted text from '{uploaded_file.name}'.\")\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred while processing '{uploaded_file.name}': {e}\")\n",
        "\n",
        "        if all_pdf_text:\n",
        "            st.subheader(\"Extracted Text\")\n",
        "            st.text_area(\"Full text from PDF(s)\", all_pdf_text, height=300)\n",
        "\n",
        "            text_splitter = RecursiveCharacterTextSplitter(\n",
        "                chunk_size=1000, chunk_overlap=200\n",
        "            )\n",
        "            splits = text_splitter.split_text(all_pdf_text)\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "            vectordb = FAISS.from_texts(splits, embeddings)\n",
        "\n",
        "            llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=openai_api_key)\n",
        "            st.session_state.qa_chain = RetrievalQA.from_chain_type(\n",
        "                llm, retriever=vectordb.as_retriever()\n",
        "            )\n",
        "            query = \"Summarize the content of the PDF(s).\"\n",
        "            summary = st.session_state.qa_chain.run(query)\n",
        "            st.write(\"---\")\n",
        "            st.subheader(\"Summary\")\n",
        "            st.write(summary)\n",
        "            st.write(\"---\")\n",
        "            st.write(f\"Token count: {count_tokens(all_pdf_text)}\")\n",
        "\n",
        "    if st.session_state.qa_chain:\n",
        "        st.subheader(\"Chat with your Documents (RAG)\")\n",
        "        st.write(\"Ask questions about the uploaded documents. Type 'exit' to stop.\")\n",
        "\n",
        "        if \"messages\" not in st.session_state:\n",
        "            st.session_state.messages = []\n",
        "\n",
        "        for message in st.session_state.messages:\n",
        "            with st.chat_message(message[\"role\"]):\n",
        "                st.markdown(message[\"content\"])\n",
        "\n",
        "        if prompt := st.chat_input(\"Ask a question:\"):\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(prompt)\n",
        "\n",
        "            if prompt.lower() != \"exit\":\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    response = st.session_state.qa_chain.run(prompt)\n",
        "                    st.markdown(response)\n",
        "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e157bca",
        "outputId": "e9996127-04e3-425d-beba-2b58b2db12d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘pages’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff02d177",
        "outputId": "2740ee1c-af8f-4fa0-e3e9-ad1b169b485e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting pages/AboutUs.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pages/AboutUs.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"About Us\")\n",
        "\n",
        "st.write(\"\"\"\n",
        "\n",
        "My initial project scope on Padlet was a simple RAG that reads the FAQ section of Archives Online, and provides information to users of the RAG Tool. But later on I wanted to try something else that is way beyond my capability, but if successful, would be a practical tool that I will see myself using. That is to convert the PDFs of speeches on the Archives Online website into text using OCR function. Here's a link to the speeches where you can download the PDFs to try: https://www.nas.gov.sg/archivesonline/speeches/search-result?search-type=advanced&speaker=Ong+Teng+Cheong\n",
        "\n",
        "I had some limitations - AISAY, which I had initially wanted to try out, were still in the midst of preparing the tool for use. Hence, I tried PyTesseract OCR as recommended by Mr Aldrian. Unfortunately, I soon found out that I had a bigger problem - the version of my MAC OS is too outdated. I am unable to download and install the Tesseract packages successfully in my local machine, and I am also unable to install and run Visual Studio Code. The browser version of VS Code is unable to use the terminal function, so that also takes away access. Hence I am trying a workaround by using Google Colab and running Streamlit from Colab instead. But this will mean that the Streamlit link can only be used when the Colab notebook is being run.\n",
        "\n",
        "The main objective of this tool is to extract text from the PDF documents on Archives Online using OCR.\n",
        "\n",
        "These are the features that I wanted:\n",
        "- To allow users to upload their own PDFs into the tool\n",
        "- To allow for uploading of multiple files\n",
        "- To summarize the text extracted from the PDFs\n",
        "\n",
        "Bonus:\n",
        "- To display the full text of the document after OCR.\n",
        "- Add a RAG (Retrieval-Augmented Generation) function after the summary is provided. This function should allow for multiple queries of all uploaded documents until the user types 'exit'.\n",
        "- Include instructions for users on how to use the RAG functionality.\n",
        "\n",
        "I MUST admit that Gemini helped to make the functions possible. At my current level, I am definitely unable to code all these by myself. As you can see from this notebook, Gemini was the one who helped me with much of the code.\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdcc02ca",
        "outputId": "4fd280ac-7c6f-4a7e-d630-747d8559697a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae64a3ad",
        "outputId": "801ef09c-6904-4c8e-a373-e6e6e4e1ab6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting pages/Methodology.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile pages/Methodology.py\n",
        "import streamlit as st\n",
        "import graphviz\n",
        "\n",
        "st.title(\"Methodology\")\n",
        "\n",
        "st.header(\"Process Flowchart\")\n",
        "\n",
        "# Create a new directed graph\n",
        "graph = graphviz.Digraph()\n",
        "\n",
        "# Add nodes for each step in the process\n",
        "graph.node(\"A\", \"User uploads PDF(s)\")\n",
        "graph.node(\"B\", \"Extract text using OCR\")\n",
        "graph.node(\"C\", \"Display extracted text\")\n",
        "graph.node(\"D\", \"Summarize the text\")\n",
        "graph.node(\"E\", \"Display summary\")\n",
        "graph.node(\"F\", \"Chat with documents (RAG)\")\n",
        "\n",
        "# Add edges to show the flow\n",
        "graph.edge(\"A\", \"B\")\n",
        "graph.edge(\"B\", \"C\")\n",
        "graph.edge(\"C\", \"D\")\n",
        "graph.edge(\"D\", \"E\")\n",
        "graph.edge(\"E\", \"F\")\n",
        "\n",
        "# Display the flowchart\n",
        "st.graphviz_chart(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef943316",
        "outputId": "13ac31e0-7c2d-41c6-f789-0cd13e19a9e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.168.2.60\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://evil-newt-100.loca.lt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "!streamlit run /content/app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOGb7JwJVpi9WBpmDXlQ3vp",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
